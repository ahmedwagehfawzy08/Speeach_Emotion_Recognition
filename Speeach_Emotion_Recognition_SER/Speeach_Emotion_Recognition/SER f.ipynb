{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd34e04-c1be-410f-9e58-6b52b9c2f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display as disp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM,TimeDistributed,Flatten,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fde815-dc44-40b3-8fa1-c5445a8523a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation\n",
    "path= 'D:\\\\emotions\\\\'\n",
    "\n",
    "def load_data(path):\n",
    "    \n",
    "    f_emotions= []\n",
    "    f_pathes = []\n",
    "\n",
    "    folders = os.listdir(path)\n",
    "    for folder in folders:\n",
    "        files = os.listdir(path + folder)\n",
    "        for file in files:\n",
    "            step = file.split('.')[0]\n",
    "            step = step.split('-')[2]\n",
    "            #print(int(step))\n",
    "            f_emotions.append(int(step))\n",
    "            f_pathes.append(path + folder + os.sep + file)\n",
    "    return [f_emotions,f_pathes]         \n",
    "\n",
    "def get_emotions(number):\n",
    "    info={1 : 'neutral', \n",
    "          2 : 'calm', \n",
    "          3 : 'happy', \n",
    "          4 : 'sad', \n",
    "          5 : 'angry', \n",
    "          6 : 'fearful', \n",
    "          7 : 'disgust', \n",
    "          8 : 'surprised'}\n",
    "    return info[number]\n",
    "\n",
    "emotions,pathes = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2089a-33bb-44e6-9a7f-d28e1481373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path):\n",
    "    data, sample_rate = librosa.load(path, duration=2.4, offset=0.6)\n",
    "    return data, sample_rate\n",
    "\n",
    "def draw_wave(path,data, sr):\n",
    "    # data, sr=librosa.load(path)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title('Audio wave ::'+path,size=12)\n",
    "    disp.waveshow(data,sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def draw_spectogram(path,data, sr):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    #data, sr=librosa.load(path)\n",
    "    x=librosa.stft(data)\n",
    "    xdb=librosa.amplitude_to_db(abs(x))\n",
    "    plt.title('spectogram for wave ::'+path,size=12)\n",
    "    disp.specshow(xdb,sr=sr,x_axis='time',y_axis='hz')\n",
    "    plt.show()\n",
    "    \n",
    "def add_noise(data, sr):\n",
    "    noise=0.035*np.random.uniform()*np.amax(data)\n",
    "    data+=noise*np.random.normal(size=data.shape[0])\n",
    "    \n",
    "    return data, sr\n",
    "\n",
    "def shift(data,sr):\n",
    "    shift_range=int(np.random.uniform(low=-5,high=5)*1000)\n",
    "    shifted=np.roll(data,shift_range)\n",
    "    \n",
    "    return shifted, sr\n",
    "\n",
    "def pitch(data,sr,factor=0.7):\n",
    "    pitched=librosa.effects.pitch_shift(y=data,sr=sr,n_steps=factor)\n",
    "    \n",
    "    return pitched, sr\n",
    "\n",
    "def stretch(data,sr, rate=0.85):\n",
    "    stretched=librosa.effects.time_stretch(y=data,rate=rate)\n",
    "    \n",
    "    return stretched, sr\n",
    "\n",
    "# feature Extraction MFCCs:\n",
    "\n",
    "def feature_extraction(data,sr):\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "def processing_audio(data,sr,options):\n",
    "    funcs=random.choice(options)\n",
    "    \n",
    "    if funcs== 'standard':\n",
    "        processed=data\n",
    "    else:\n",
    "        processed, _=funcs(data,sr)\n",
    "        \n",
    "    return processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4ebca-9062-4bf7-9432-2eac05a402f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(path):\n",
    "    data, sample_rate = read_audio(path)\n",
    "    funcs = ['standard', add_noise, shift, pitch, stretch]\n",
    "    features = []\n",
    "    for _ in range(3):  # Augment data three times for each file\n",
    "        func1_data = processing_audio(data, sample_rate, funcs)\n",
    "        func2_data = processing_audio(func1_data, sample_rate, funcs)\n",
    "        feature = feature_extraction(func2_data, sample_rate)\n",
    "        if feature.shape == (20, 104):\n",
    "            features.append(feature)\n",
    "    return features\n",
    "\n",
    "    return features\n",
    "def display(number):\n",
    "    data,sapmle_rate=read_audio(pathes[number])\n",
    "    mfcc_features=feature_extraction(data,sapmle_rate)\n",
    "    print(len(mfcc_features))\n",
    "    feature_extraction(data,sapmle_rate)\n",
    "    print(get_emotions(emotions[number]))\n",
    "    data,sapmle_rate=add_noise(data,sapmle_rate)\n",
    "    data,sapmle_rate=shift(data,sapmle_rate)\n",
    "    data,sapmle_rate=pitch(data,sapmle_rate)\n",
    "    data,sapmle_rate=stretch(data,sapmle_rate)\n",
    "    draw_wave(pathes[number],data,sapmle_rate)\n",
    "    draw_spectogram(pathes[number],data,sapmle_rate)\n",
    "    \n",
    "    return data, sapmle_rate\n",
    "\n",
    "\n",
    "d,sr=display(70)    \n",
    "Audio(data=d,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca78fc3-be3e-41ca-aa63-c0ab6183a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indx in range(len(pathes)):\n",
    "    print(emotions[indx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894e884-3cab-4965-b184-ed95d7df3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=OneHotEncoder()\n",
    "encoder.fit_transform(np.array([1,2,3,4,5,6,7,8]).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5056a-483d-45aa-a8b0-8ae5720fdce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for indx in range(len(pathes)):\n",
    "    value=get_features(pathes[indx])\n",
    "    if value !=[]:\n",
    "        for item in value:\n",
    "            x.append(item)\n",
    "            y.append(np.eye(8)[emotions[indx]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af813f-8fa6-4a27-b1f7-cefa0bfcb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(np.array(x),np.array(y),test_size=0.2,random_state=11,shuffle=True)\n",
    "print('train x shape',x_train.shape)\n",
    "print('test x shape',x_test.shape)\n",
    "print('train y shape',y_train.shape)\n",
    "print('test y shape',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa93e98-0fc5-4a51-ba43-074e32284964",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.expand_dims(x_train, axis=3)\n",
    "trainX = np.expand_dims(trainX, axis=3)\n",
    "trainX = np.swapaxes(trainX, 1 ,2)\n",
    "print('train X:',trainX.shape)\n",
    "\n",
    "#testX = np.expand_dims(x_test, axis=3)\n",
    "#testX = np.expand_dims(testX, axis=3)\n",
    "#trainX = np.swapaxes(testX, 1 ,2)\n",
    "#print('test X:',testX.shape)\n",
    "testX = np.expand_dims(x_test, axis=3)\n",
    "testX = np.expand_dims(testX, axis=3)\n",
    "testX = np.swapaxes(testX, 1, 2)  # Corrected line\n",
    "print('test X:', testX.shape)\n",
    "\n",
    "\n",
    "inputShape = trainX.shape[1:]\n",
    "inputShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75313c-8903-4562-a7f3-9245455e620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(inputShape):\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(32, 3, padding='same', activation='relu'), input_shape=inputShape))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(LSTM(128, return_sequences=True))  # Increased LSTM units\n",
    "    model.add(Dropout(0.5))  # Added Dropout layer\n",
    "\n",
    "    model.add(LSTM(128))  # Added another LSTM layer\n",
    "    model.add(Dropout(0.5))  # Added Dropout layer\n",
    "\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units=8, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507db4d0-6430-4677-af40-8aa65dad09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(inputShape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091843a-9b1e-48fb-a6dd-d40de943eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer= opt,loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor= '',factor=0.6,verbose=1,patience=5,min_lr=1e-8)\n",
    "stop = EarlyStopping(monitor='val_los',patience=7)\n",
    "\n",
    "hist= model.fit(trainX,y_train,batch_size=256,epochs=100,validation_data=(testX,y_test),callbacks=[reduce,stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9215b631-d000-4452-aeaa-561a4025f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('The accuracy: ',model.evaluate(testx,y_test)[1]*100,'%')\n",
    "train_loss=hist.history['loss']\n",
    "test_loss=hist.history['val_loss']\n",
    "train_accuracy=hist.history['accuracy']\n",
    "test_accuracy=hist.history['val_accuracy']\n",
    "\n",
    "epochs= [value for value in range(100)]\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "fig.set_size_inches(15,6)\n",
    "ax[0].plot(epochs,train_loss,label='Training Loss')\n",
    "ax[0].plot(epochs,test_loss,label='Testing Loss')\n",
    "ax[0].set_title('Testing & Training Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "\n",
    "\n",
    "ax[1].plot(epochs,train_accuracy,label='Training Accuracy')\n",
    "ax[1].plot(epochs,test_accuracy,label='Testing Accuracy')\n",
    "ax[1].set_title('Testing & Training Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "\n",
    "model.save('D:\\\\emotions\\\\emotion_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce626d-78fd-48d6-8751-4f9407faa27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model = load_model('D:\\\\emotions\\\\emotion_model2.h5')\n",
    "y_pred = emotion_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a21006-8ae6-47ba-bf21-a79f88524ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predY=encoder.inverse_transform(y_pred)\n",
    "testY=encoder.inverse_transform(y_test)\n",
    "\n",
    "emotions_predict = [get_emotions(value) for value in predY.flatten()]\n",
    "emotions_actual = [get_emotions(value) for value in testY.flatten()]\n",
    "\n",
    "df = pd.DataFrame(columns=['Actual Emotions','Predicted Emotions'])\n",
    "\n",
    "df['Actual Emotions'] = emotions_actual\n",
    "df['Predicted Emotions'] = emotions_predict\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443b386-f79c-4775-8753-37d4583642f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(testY,predY)\n",
    "\n",
    "emts= [get_emotions(em) for em in encoder.categories_[0]]\n",
    "\n",
    "cmt =pd.DataFrame(cm, index= emts, columns = emts)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cmt, annot=True, fmt='', cmap='BuGn')\n",
    "plt.title('Confusion Matrix',size=15)\n",
    "plt.xlabel('Predicted Emotions', size=15)\n",
    "plt.ylabel('Actual Emotions', size=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
